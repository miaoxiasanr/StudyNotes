- [渲染管线](#渲染管线)
  - [CPU和GPU的区别](#cpu和gpu的区别)
    - [CPU（基于低延时的设计）](#cpu基于低延时的设计)
    - [GPU（基于大的吞吐量设计）](#gpu基于大的吞吐量设计)
  - [渲染管线](#渲染管线-1)
    - [CPU渲染逻辑](#cpu渲染逻辑)
    - [GPU渲染管线](#gpu渲染管线)

# 渲染管线
## CPU和GPU的区别
![](https://pic2.zhimg.com/80/894e6d2f20921e7c8be985bbb0dac5d5_720w.jpg?source=1940ef5c)

从上图可以看到：
    Cache,local memory:CPU>GPU
    Threads:GPU>CPU
    Registers（寄存器）:GPU>CPU
    SIMD Unit（同一时间内执行同一条指令）:GPU>CPU
### CPU（基于低延时的设计）
* CPU有强大的ALU(算术计算单元),他可以在很少的时钟周期内完成算术计算
* 大的缓存也可以降低延时。保存很多的数据在缓存里面，但需要访问的这些数据，只要之前访问过的，可以在缓存里面直接取
* 复杂的逻辑控制单元。当程序含有多个分支时，通过提供分支预测的能力降低延时

### GPU（基于大的吞吐量设计）
* GPU的特点是有很多的ALU和很少的cache，缓存的目的不是为了保存后面需要访问的数据的，这点和CPU是不同的，而是为了Thread提供服务的。如果很多线程需要访问同一个相同的数据，缓存会合并这些访问，再去获取数据，获取数据后cache会转发这个数据给对应的线程，这个过程会带来延时的问题。
* GPU的控制单元可以把多个访问合并成少的访问
* GPU虽然有延时的问题，却又有非常多的Thread，为了平衡内存延时的问题，可以充分利用多的ALU的特性达到一个大的吞吐量的效果

## 渲染管线

![](https://picx.zhimg.com/v2-579bdb7ac479bbbcf52358ca67725bd6_1440w.jpg?source=172ae18b "渲染管线示意图")
### CPU渲染逻辑
CPU阶段渲染步骤
* 进行剔除(Culling)工作：剔除主要分3类
> * 视锥体剔除(Frustum Culling)：如果场景中的物体在视锥体的外部，那么说明物体不可见，不需要对其进行渲染
> * 层级剔除(Layer Culling Mask)：通过给物体设置不同的层级，让摄像机不渲染某一层
> * 遮挡剔除(Occlusion Culling)：当一个物体被其他物体遮挡而不在摄像机的可视范围内时不对其进行渲染
* 设置渲染顺序：渲染顺序主要是有渲染队列(Render Qunue)的值决定的，不透明队列(Render Queue<2500)，根据摄像机距离从前往后排序，这样先渲染进的物体，远处的物体被遮挡剔除；半透明队列(Render Queue>2500)，根据摄像机距离从后往前排，这是为了渲染正确性；例如半透明黄色和蓝色物体，不同的渲染顺序会出现不一样的颜色
* 打包数据：将数据打包发送给GPU，这些数据主要包含三部分，分别是：
> * 模型信息：顶点坐标，法线，UV，切线，顶点颜色，索引列表
> * 变换矩阵：世界变换矩阵，相机矩阵，模型矩阵
> * 灯光，材质参数：Shader，材质参数，灯光信息
* 调用SetPass Call，Draw Call
> * SetPass Call:Shader脚本中一个Pass语义块就是一个完整的渲染流程，一个着色器可以包含多个Pass语义块，每当GPU调用一个Pass之前，就会产生一个SetPassCall

> * Draw Call:CPU每次调用图像编程接口命令GPU渲染的操作称为一次DrawCall，就是一次渲染命令的调用，他指向一个需要被渲染的图元列表，不包含任何材质信息，GPU收到信息就会根据渲染状态和输入的所有顶点数据来计算，最终输出像素。
> ![](https://pic1.zhimg.com/80/v2-385c4e1a6da6e85f0725f1dca9a801cc_720w.jpg)

**CPU渲染阶段最重要的输出是渲染所需的几何信息，即渲染图元(Rendering Primitives)，渲染图元就是点，线，三角形等，这些信息会传递给GPU进行管线处理**

### GPU渲染管线

![alt 渲染管线示意图](https://img2020.cnblogs.com/blog/1544400/202111/1544400-20211107150945162-1780333474.jpg "渲染管线示意图")
* **顶点处理**
  * 顶点着色器(vertex shader)
    顶点着色器的处理单位是**顶点**，也就是说，输入进来的每个顶点都会调用一次顶点着色器，他主要是执行坐标转换和逐顶点光照的任务
    > 坐标转换:将顶点坐标从模型空间转换到齐次裁剪空间中，通过MVP(model,view,projection)矩阵转换得到
    > ![](https://positiveczp.github.io/%E7%BB%86%E8%AF%B4%E5%9B%BE%E5%BD%A2%E5%AD%A6%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF_files/Image%20[11].png  "MVP矩阵")
      * 投影
        * 视锥体
        ![视锥体](https://positiveczp.github.io/%E7%BB%86%E8%AF%B4%E5%9B%BE%E5%BD%A2%E5%AD%A6%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF_files/Image%20[14].png  "视锥体")
        * 正交投影最终矩阵
            ![](https://positiveczp.github.io/%E7%BB%86%E8%AF%B4%E5%9B%BE%E5%BD%A2%E5%AD%A6%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF_files/Image%20[15].png)
        * 透视投影最终矩阵
            ![](https://positiveczp.github.io/%E7%BB%86%E8%AF%B4%E5%9B%BE%E5%BD%A2%E5%AD%A6%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF_files/Image%20[17].png)


    > 逐顶点光照：为每个顶点计算光照，然后再光栅化阶段读取图元顶点的颜色对齐边界和内部进行线性差值
  * 曲面细分着色器(Tessellation shader)
    可选着色器，主要对三角面进行细分，来增加物体表面的三角面的数量，使得离摄像机越近的物体有更加丰富的细节，而远离摄像机的物体具有较少的细节；
  * 几何着色器(Geometry shader)
    可选着色器，以完整的图元（比如点）作为输入数据，输出可以是一个或多个其他的图元（比如三角面）或者不输出任何的图元


* **图元装配**
  * 裁剪(Cliping)
    只有当图元部分或全部位于视锥体时，我们才会将他送到流水线的下个阶段，也就是光栅化阶段，而完全位于视锥体外面的图元会被裁减掉，不会对他们进行渲染，部分在视锥体图元，会裁剪外部的部分图元.例如一个线段的两个顶点，一个在视锥体外面，一个在里面，那么位于视锥体外面的就会被裁减掉，而且在视锥体与线段的交界处产生新的代替视野外部的顶点
    ![](https://positiveczp.github.io/%E7%BB%86%E8%AF%B4%E5%9B%BE%E5%BD%A2%E5%AD%A6%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF_files/Image%20[22].png)
  * 标椎化设备坐标(Normalized Device Coordinates，NDC)
    在裁剪空间的基础上，进行透视除法后得到NDC坐标，将坐标从裁剪空间的（-W,-W,-W)变换成(-1,-1,-1)，获取NDC坐标是为了实现屏幕坐标的转换与硬件无关
  * 背面剔除(Back-Face Culling)
    ![](https://positiveczp.github.io/%E7%BB%86%E8%AF%B4%E5%9B%BE%E5%BD%A2%E5%AD%A6%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF_files/Image%20[23].png)
    背面剔除指的是剔除那些背对摄像机的图元，如上图所示，图元t1背对摄像机需要被剔除，而t2则需要被保留。利用三角形顶点的环绕顺序来确定所谓的正面和背面.
    通常情况下，三角形的3个顶点是逆时针顺序(couter-clockwise,ccw)进行排列时，我们会认为是正面，而顺时针(clockwise,cw)排序时，会认为是正面
    ![](https://positiveczp.github.io/%E7%BB%86%E8%AF%B4%E5%9B%BE%E5%BD%A2%E5%AD%A6%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF_files/Image%20[24].png)
  * 屏幕映射(Screenmapping)
    屏幕映射的任务是把每个图元的x和y坐标转换到屏幕坐标系上,我们把场景渲染到一个窗口上，窗口的范围是最小的窗口坐标(x1,y1)到最大坐标(x2,y2)，由于我们的输入范围是-1到1，可以想象到这是一个缩放的过程，且屏幕映射不会对z坐标做任何处理
    ![](https://img2020.cnblogs.com/blog/1544400/202111/1544400-20211107151108051-1948845014.png)

* **光栅化**
  该阶段是将变换到屏幕空间的图元离散成片元的过程
  ![](https://positiveczp.github.io/%E7%BB%86%E8%AF%B4%E5%9B%BE%E5%BD%A2%E5%AD%A6%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF_files/Image%20[31].png)
  * 三角形设置(Triangle Setup)
    从上一阶段获得的图元的顶点信息，也就是三角面每条边的两个端点，但如果要得到整个三角形网格对像素的覆盖情况，我们就必须计算每条边的像素坐标，为了能计算边界像素的坐标信息，就需要得到三角形边界的表示方式，这样的一个计算三角形网格表示数据的过程叫做三角形设置
  * 三角形遍历(Triangle Traversal)
    三角形遍历阶段会根据上一阶段的计算结果来判断一个三角形网格覆盖了哪些像素，并使用三角网格3个顶点的顶点信息对覆盖区域的像素进行插值。
    这一步的输出得到一个片元序列，值得注意的是，一个片元并不是真正意义上的像素，而是包含了很多状态下的集合，这些状态用于计算每个像素的最终颜色，这些状态包括但不限于屏幕坐标，深度值，顶点颜色，以及几何阶段输出的顶线信息，例如法线，纹理坐标等；

* **片段着色器**
  * 纹理贴图(Textures)
    也称纹理映射，是将图像信息映射到三角形网格上的技术，以此来增加物体表面的细节，令物体更具有真实感
    纹理映射就是进行纹素和像素对应的过程
    ![](https://img2020.cnblogs.com/blog/1544400/202111/1544400-20211107151205902-1021477964.png)
    如上图右边是一副32*32的贴图,它是由一格一格的像素组成，每个像素都有一个地址，这个地址就叫纹理坐标UV，U是横坐标，V是纵坐标，UV坐标一般归一化到[0,1]之间，如果超过这个范围，就需要指定纹理坐标的寻址方式，也叫做平铺方式
  * 光照计算(Lighting)
    光照是有直接光和间接光组成，
    * 冯氏光照模型(Phong Light Model)
        ![](https://img2020.cnblogs.com/blog/1544400/202111/1544400-20211107151503881-1730536408.png)
        * 漫反射(Diffuse)
            漫反射是投射在粗糙表面上的光向各个方向反射的现象，虽然入射光方向互相平行，但由于法线方向不一致，会造成反射光线向不同的方向无规则的反射
            ~~~GLSL
            vec3 norm=normalize(Normal);//单位法向量
            vec3 lightDir=normalize(lightPos-FragPos);//单位光线方向向量

            float diff=max(dot(norm,lightDir),0.0);//点乘取到两个向量之间的角度，角度越小，越->1,大于90度，则结果小于0，需要合0取最大值
            vec3 diffuse=diff*lightColor;//角度越大，漫反射光照越亮
            ~~~
        * 镜面反射(Specular)
            镜面反射是指若反射面比较光滑，当平行入射的光线射到这个反射面时，会平行的向一个方向反射出来
            ~~~GLSL

            in vec3 FragPos;

            uniform vec3 viewPos;//摄像机的世界位置坐标

            vec3 norm=normalize(Normal);
            vec3 lightDir=normalize(lightPos-FragPos);

            vec3 viewDir=normalize(viewPos-FragPos);//模型到视线的向量
            vec3 reflectDir=reflect(-lightDir,norm);//光线经过法线折射出来光线的向量
            //reflect函数 ：要求第一个参数是光源指向片段的向量，第二个参数是一个法向量
            //-lightDir,取反代表是光线方向的反方向，从片段指向光源

            float spec=pow(max(dot(viewDir,reflectDir),0.0),32);
            vec3 specular=specularStrength *spec * lightColor;
            //首先计算视线方向与反射方向的点乘(并确保他不是负值)，然后取他的32次幂，这个32是高光的反光度
            //一个物体的反光度越高，反射光的能力越强，散射得越少，高光点就会越小
            ~~~
        * 环境光(Ambient)
            环境光分量是模拟全局光照效果的，其实就是在物体光照信息基础上叠加一个比较小的光照常量，用来表示场景中其他物体反射的间接光照
            ~~~GLSL
            uniform vec3 lightColor;

            float ambientstrength=0.1;
            vec3 ambient=ambientstrength*lightColor;
            ~~~

* **输出合并**
  * Alpha测试
    颜色一般采用RGBA四分量表示，其中颜色的Alpha值用来表示物体本身的不透明度，Alpha可以根据片段颜色的Alpha值来裁剪片段；
    ![](https://learnopengl-cn.github.io/img/04/03/blending_no_discard.png)
    ~~~GLSL
    #version 330 core

    in vec2 TexCoords;

    out vec4 FragColor;

    uniform sampler2D texture1;
    void main()
    {
	    vec4 texColor=texture(texture1,TexCoords);
	    if(texColor.a<0.1)
	    {
		    discard;
	    }
	    FragColor=texColor;
    }
    ~~~
    ![](https://learnopengl-cn.github.io/img/04/03/blending_discard.png)
  * 模板测试(Stencil Test)
    可以理解为一个模子Mask，通过Mask的值来控制那些片段的可见性，无法通过的片段将被丢弃
    ![](https://positiveczp.github.io/%E7%BB%86%E8%AF%B4%E5%9B%BE%E5%BD%A2%E5%AD%A6%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF_files/Image%20[81].png)
  * 深度测试
    在日常生活中，近处的物体会遮挡住远处的物体，这种效果可以通过深度测试来实现。他通过将深度缓冲中的值与当前片段的深度值进行判断，计算是否需要更新深度缓存和颜色缓存，如果不需要则将该片段丢弃
    ![](https://positiveczp.github.io/%E7%BB%86%E8%AF%B4%E5%9B%BE%E5%BD%A2%E5%AD%A6%E6%B8%B2%E6%9F%93%E7%AE%A1%E7%BA%BF_files/Image%20[82].png)
